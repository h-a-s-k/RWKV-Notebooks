{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Updates](https://github.com/h-a-s-k/RWKV-Notebooks)\n"
      ],
      "metadata": {
        "id": "hq7DhSMBj9De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "cs3G0Pu-il2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create and mount folders { display-mode: \"form\" }\n",
        "drive_dir = '/content/drive'\n",
        "\n",
        "#@markdown Avoid spaces<br>`model_dir` is relative to your Google Drive root folder`\n",
        "model_dir = 'AI/RWKV' #@param {type:\"string\"}\n",
        "#@markdown relative to `model_dir`\n",
        "tuned_dir = 'infctx' #@param {type:\"string\"}\n",
        "#@markdown relative to `tuned_dir`\n",
        "dataset_folder = 'mydata' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Leave empty if you don't understand\n",
        "wandb_project = '' #@param {type:\"string\"}\n",
        "\n",
        "output_path = f\"{drive_dir}/MyDrive/{model_dir}\"\n",
        "checkpoint_dir = f\"{output_path}/{tuned_dir}\"\n",
        "\n",
        "dataset_location = f\"{checkpoint_dir}/dataset\"\n",
        "jsonl_folder = f\"{dataset_location}/{dataset_folder}\"\n",
        "binidx_filename = f\"{dataset_folder}_text_document\" # hardcoded suffix\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(drive_dir, force_remount=True)\n",
        "\n",
        "from os import makedirs\n",
        "makedirs(f\"{checkpoint_dir}\", exist_ok=True)\n",
        "makedirs(f\"{jsonl_folder}\", exist_ok=True)\n",
        "\n",
        "print(f\"-----\\nSaving checkpoints to {checkpoint_dir}\")\n",
        "print(f\"-----\\nIf you want to tokenize into binidx,\\nplace your jsonl dataset file(s) in {jsonl_folder}\")\n",
        "print(f\"otherwise move both pre-made .idx and .bin files in {dataset_location}\")"
      ],
      "metadata": {
        "id": "kyiI5xU4xh7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone needed repos and install packages\n",
        "#!nvidia-smi\n",
        "\n",
        "!rm -rf RWKV\n",
        "!git clone https://github.com/PicoCreator/RWKV-LM-LoRA.git RWKV\n",
        "%cd RWKV\n",
        "!git switch picocreator-dev-infctx\n",
        "!git pull\n",
        "%cd /content/\n",
        "\n",
        "###### RWKV\n",
        "#  https://hub.docker.com/r/uilicious/rwkv-dev-infctx-env/tags\n",
        "#  https://github.com/PicoCreator/RWKV-LM-LoRA/tree/cd69f85cc94d353d6883c1ec2deb30c1b5d4e48e#environment-setup\n",
        "#  pytorch\n",
        "!pip install torch==2.0.1 torchvision torchaudio lightning==2.0.4 deepspeed==0.9.5 --quiet\n",
        "#  other\n",
        "!pip install datasets transformers ninja wandb numexpr sentencepiece jsonargparse 'jsonargparse[signatures]' --quiet\n",
        "\n",
        "###### json2binidx_tool\n",
        "!git clone https://github.com/Abel2076/json2binidx_tool.git GPT-NeoX\n",
        "!pip install 'tokenizers>=0.13.*' 'numpy>=1.23.*' 'lm_dataformat>=0.0.20' 'ftfy>=6.1.*' 'tqdm>=4.65.*' --quiet\n",
        "\n",
        "###### Extra\n",
        "!pip install huggingface_hub --quiet\n",
        "\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "id": "WwCaLe3inUs1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load models\n",
        "%cd /content/\n",
        "model_name = \"RWKV-4-World-0.4B\" #@param [\"RWKV-4-World-1B5-v1\", \"RWKV-4-Raven-1B5-v12\", \"RWKV-4-World-0.4B\", \"RWKV-4-Pile-430M\", \"RWKV-4-World-0.1B\", \"RWKV-4-Pile-169M\"]\n",
        "#@markdown Check to continue from a previous checkpoint in your `tuned_dir`\n",
        "restore_checkpoint = False #@param {type:\"boolean\"}\n",
        "\n",
        "import huggingface_hub\n",
        "from huggingface_hub import hf_hub_url, hf_hub_download\n",
        "\n",
        "model_filename = f\"{model_name}.pth\"\n",
        "if model_name == \"RWKV-4-Pile-169M\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-pile-169m\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-Pile-169M-20220807-8023.pth\")\n",
        "    n_layer = 12\n",
        "    n_embd = 768\n",
        "    model_world = False\n",
        "if model_name == \"RWKV-4-World-0.1B\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-world\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-World-0.1B-v1-20230520-ctx4096.pth\")\n",
        "    n_layer = 12\n",
        "    n_embd = 768\n",
        "    model_world = True\n",
        "if model_name == \"RWKV-4-Pile-430M\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-pile-430m\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-Pile-430M-20220808-8066.pth\")\n",
        "    n_layer = 24\n",
        "    n_embd = 1024\n",
        "    model_world = False\n",
        "if model_name == \"RWKV-4-World-0.4B\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-world\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-World-0.4B-v1-20230529-ctx4096.pth\")\n",
        "    n_layer = 24\n",
        "    n_embd = 1024\n",
        "    model_world = True\n",
        "if model_name == \"RWKV-4-Raven-1B5-v12\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-raven\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-Raven-1B5-v12-Eng98%-Other2%-20230520-ctx4096.pth\")\n",
        "    n_layer = 24\n",
        "    n_embd = 2048\n",
        "    model_world = False\n",
        "if model_name == \"RWKV-4-World-1B5-v1\":\n",
        "    model_repo = f\"BlinkDL/rwkv-4-world\"\n",
        "    model_url = hf_hub_url(repo_id=f\"{model_repo}\", filename=\"RWKV-4-World-1.5B-v1-fixed-20230612-ctx4096.pth\")\n",
        "    n_layer = 24\n",
        "    n_embd = 2048\n",
        "    model_world = True\n",
        "\n",
        "from os.path import isfile, getctime, getmtime, basename\n",
        "if isfile(model_filename) == False:\n",
        "  print(f\"Downloading {model_url}\")\n",
        "  !curl -L $model_url -o $model_filename\n",
        "\n",
        "!ls -alh /content/$model_filename\n",
        "\n",
        "checkpoint_final = f'{checkpoint_dir}/{model_name}'\n",
        "!mkdir -p $checkpoint_final\n",
        "\n",
        "from glob import glob\n",
        "if restore_checkpoint == True:\n",
        "  checkpoint_folders = glob(f\"{checkpoint_dir}/{model_name}/*.ckpt\")\n",
        "  if len(checkpoint_folders) < 1:\n",
        "    print(f\"-----\\nNo checkpoint folders found inside {checkpoint_dir}/{model_name}/\")\n",
        "  else:\n",
        "    checkpoint_path = max(checkpoint_folders, key=getmtime)\n",
        "    print(f\"-----\\nRestoring from {checkpoint_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FseBsqUtdBZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "oh8XRqBHbzlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create dataset out of jsonl files { display-mode: \"form\" }\n",
        "#@markdown In case you mounted your drive before copying the jsonl files over, re-run the setup part again before running this.<br><br><i>\"The goal of ftfy is to take in bad Unicode and output good Unicode, for use in your Unicode-aware code.\"</i>\n",
        "use_ftfy = True #@param {type:\"boolean\"}\n",
        "append_endoftext = True #@param {type:\"boolean\"}\n",
        "#@markdown <hr>example-1.jsonl file contents:\n",
        "#@markdown <br><code>{\"text\":\"Text train one\"}<br>{\"text\":\"Text two\"}<br>{\"text\":\"Text another three\"}</code>\n",
        "\n",
        "%cd /content/\n",
        "print(f\"Tokenizing jsonl files in {jsonl_folder}\")\n",
        "\n",
        "if model_world == True:\n",
        "  tokenizer = 'RWKVTokenizer'\n",
        "  vocab = './GPT-NeoX/rwkv_vocab_v20230424.txt'\n",
        "else:\n",
        "  tokenizer = 'HFTokenizer'\n",
        "  vocab = './GPT-NeoX/20B_tokenizer.json'\n",
        "\n",
        "cmd = f'''\n",
        "python ./GPT-NeoX/tools/preprocess_data.py \\\n",
        "--input {jsonl_folder} \\\n",
        "--output-prefix {jsonl_folder} \\\n",
        "--dataset-impl mmap \\\n",
        "--tokenizer-type {tokenizer} \\\n",
        "--vocab {vocab}'''\n",
        "\n",
        "if append_endoftext:\n",
        "  cmd += ' --append-eod'\n",
        "if use_ftfy:\n",
        "  cmd += ' --ftfy'\n",
        "\n",
        "print(f\"{cmd}\")\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "6J9_Hjywb2Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finetune { display-mode: \"form\" }\n",
        "#@markdown Steps of `trainer/global_step`, not the progress bar\n",
        "save_every_global_steps = 20 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Main\n",
        "#@markdown Either `target_batch_size` OR `accumulate_grad_batches` (leave one empty)\n",
        "target_batch_size = '40' #@param {type:\"string\"}\n",
        "accumulate_grad_batches = \"\" #@param {type:\"string\"}\n",
        "ctx_len = '1024' #@param ['128', '256', '512', '1024', '2048', '3072', '4096', '5120', '6144', '7168', '8192', '9216', '10240'] {type:\"string\"}\n",
        "max_epochs = 1000 #@param {type:\"integer\"}\n",
        "precision = 'bf16-mixed' #@param ['16-mixed', 'bf16-mixed', '32-true', '64-true'] {type:\"string\"}\n",
        "weight_decay = \"0.02\" #@param {type:\"string\"}\n",
        "grad_cp = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Strategy\n",
        "#@markdown `deepspeed_stage_1`: Each of your GPUs has too much vram, and you do not know what to do\n",
        "#@markdown <br>`deepspeed_stage_2` : Optimal distributed training strategy, across multiple gpu each with sufficient vram\n",
        "#@markdown <br>`deepspeed_stage_2_offload`: Reduce vram usage by offloading the optimizer state and work to cpu\n",
        "#@markdown <br>`deepspeed_stage_3`: Split up the model across multiple gpu, useful for large models, at a performance cost\n",
        "#@markdown <br>`deepspeed_stage_3_offload`: Additional offloading, for even greater performance cost\n",
        "strategy = 'deepspeed_stage_1' #@param ['deepspeed_stage_1', 'deepspeed_stage_2', 'deepspeed_stage_2_offload', 'deepspeed_stage_3', 'deepspeed_stage_3_offload'] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Extra\n",
        "lr_init = \"1e-5\" #@param {type:\"string\"}\n",
        "lr_final = \"1e-5\" #@param {type:\"string\"}\n",
        "adam_eps = \"1e-8\" #@param {type:\"string\"}\n",
        "beta1 = 0.9 #@param {type:\"number\"}\n",
        "beta2 = 0.99 #@param {type:\"number\"}\n",
        "#@markdown <hr>Number or leave empty for random\n",
        "seed = '' #@param {type:\"string\"}\n",
        "\n",
        "from datetime import datetime\n",
        "from os import environ\n",
        "environ[\"RWKV_CUDA_ON\"] = \"1\"\n",
        "environ[\"RWKV_DEEPSPEED\"] = \"1\"\n",
        "#environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# https://github.com/PicoCreator/RWKV-LM-LoRA/blob/3c9f2f0fff92c7f683b07defdc54c04d39b643bf/notebook/trainer-validation/config/baseline-1024.yaml\n",
        "config_location = f'{checkpoint_dir}/{model_name}-config.yaml'\n",
        "!rm $config_location\n",
        "\n",
        "config = open(f'{config_location}', \"w\")\n",
        "config.write(f'''\n",
        "# Generated\n",
        "seed_everything: {seed if len(seed) > 0 else 'true'} # 3941088705\n",
        "model:\n",
        "  load_model: '/content/{model_filename}'\n",
        "  n_embd: {n_embd}\n",
        "  n_layer: {n_layer}\n",
        "  vocab_size: {65536 if model_world else 50277}\n",
        "  ctx_len: {ctx_len}\n",
        "  lr_init: {lr_init}\n",
        "  lr_final: {lr_final}\n",
        "  adam_eps: {adam_eps}\n",
        "  beta1: {beta1}\n",
        "  beta2: {beta2}\n",
        "  weight_decay: {weight_decay}\n",
        "  grad_cp: {str(grad_cp).lower()}\n",
        "  torch_set_float32_matmul_precision: 'high'\n",
        "  bptt_learning: true # or 'true if offloading'\n",
        "  bptt_learning_range: -1\n",
        "data:\n",
        "  data_path: '{dataset_location}/{dataset_folder}_HF'\n",
        "  source: '{dataset_location}/{binidx_filename}'\n",
        "  tokenizer: binidx\n",
        "  custom_text_key: 'text'\n",
        "\n",
        "  test_split: 0.01\n",
        "  test_split_shuffle: false\n",
        "\n",
        "trainer:\n",
        "  accelerator: gpu\n",
        "  devices: auto\n",
        "  strategy: {strategy}\n",
        "  precision: {precision}\n",
        "  max_epochs: {max_epochs}\n",
        "  {f'accumulate_grad_batches: {accumulate_grad_batches}' if len(accumulate_grad_batches) > 0 else f'target_batch_size: {target_batch_size}'}\n",
        "\n",
        "  logger:\n",
        "    class_path: lightning.pytorch.loggers.WandbLogger\n",
        "    init_args:\n",
        "      name: '{model_name} {ctx_len}ctx | {datetime.now().strftime(\"%d %b %H:%M:%S\")}'\n",
        "      project: '{wandb_project if len(wandb_project) > 0 else ''}'\n",
        "      save_dir: .\n",
        "      version: null\n",
        "      log_model: all\n",
        "    dict_kwargs:\n",
        "      group: 'lightning 2.0.2'\n",
        "\n",
        "  callbacks:\n",
        "  - class_path: lightning.pytorch.callbacks.ModelCheckpoint\n",
        "    init_args:\n",
        "      dirpath: '{checkpoint_final}'\n",
        "      monitor: 'step'\n",
        "      mode: max\n",
        "\n",
        "      save_on_train_epoch_end: true\n",
        "      save_top_k: 1\n",
        "      save_last: true\n",
        "      every_n_train_steps: {save_every_global_steps}\n",
        "\n",
        "ckpt_path: {checkpoint_path if restore_checkpoint else 'null'}\n",
        "''')\n",
        "config.close()\n",
        "\n",
        "# Convert dataset to HF datapath format and save it\n",
        "cmd = f'''python3 /content/RWKV/RWKV-v4neo/preload_datapath.py \\\n",
        "{config_location}\n",
        "'''\n",
        "print(f\"{cmd}\")\n",
        "!{cmd}\n",
        "\n",
        "# Train\n",
        "cmd = f'''\n",
        "python3 /content/RWKV/RWKV-v4neo/lightning_trainer.py fit \\\n",
        "-c {config_location}\n",
        "'''\n",
        "print(f\"{cmd}\")\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "05K-elkHdW_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting checkpoint\n",
        "> Run \"Setup\" category before this if you haven't"
      ],
      "metadata": {
        "id": "38yMXE0hasdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export\n",
        "%cd /content/\n",
        "\n",
        "from glob import glob\n",
        "checkpoint_folders = glob(f\"{checkpoint_dir}/{model_name}/*.ckpt\")\n",
        "if len(checkpoint_folders) < 1:\n",
        "  print(f\"-----\\nNo checkpoint folders found inside {checkpoint_dir}/{model_name}/\")\n",
        "else:\n",
        "  checkpoint_path = max(checkpoint_folders, key=getmtime)\n",
        "  print(f\"-----\\nRestoring from {checkpoint_path}\")\n",
        "  cmd = f'python3 /content/RWKV/RWKV-v4neo/export_checkpoint.py -d {checkpoint_path} /content/RWKV-Exported.pth'\n",
        "  print(f\"{cmd}\")\n",
        "  !{cmd}"
      ],
      "metadata": {
        "id": "-jPTJFdSayxV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Move to drive\n",
        "cmd = f'cp /content/RWKV-Exported.pth {checkpoint_dir}/RWKV-Exported.pth'\n",
        "print(f\"{cmd}\")\n",
        "!{cmd}\n",
        "!ls -alh $checkpoint_dir/RWKV-Exported.pth"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cvwt2EktjSNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}